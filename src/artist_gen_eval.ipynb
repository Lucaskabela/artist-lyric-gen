{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artist-gen-eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLaHt-pRlrAU"
      },
      "source": [
        "## Mount Gdrive?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibNqQOEXlwnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567ebfa4-74af-4c74-ff1a-5f28bb79c19b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gao2nNRGnuR"
      },
      "source": [
        "# ****REMEMBER: change this to whatever your drive folder is\n",
        "drive_folder = \"/content/drive/My Drive/NLP CS395T/Artist-ic Endeavor\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEpWXNSvUoE5"
      },
      "source": [
        "## For Printing verses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik40uUOPTiQ1"
      },
      "source": [
        "def print_verse(filename):\n",
        "    artist_to_verses = get_artist_to_verses_model_output(filename)\n",
        "    verse = artist_to_verses[1][37]\n",
        "    text = \" \".join(verse).strip()\n",
        "    text = bpe_string_to_text(text)\n",
        "    text = clean_lines(text)\n",
        "    print(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7X9hQLbTj2J",
        "outputId": "879791a3-77b1-43cf-b791-b1ac8c6c18cd"
      },
      "source": [
        "verses_file = 'verses_sentence.json'\n",
        "print_verse('{}/{}'.format(drive_folder, verses_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i is young killer fake world you battle exploited produced of discussion every\n",
            "i is young 21 niggas world rap lder shment ism dant my sonof\n",
            "i is doggy real gangster aint analyze becoming lus ctive southern of ops christmas\n",
            "i is young freaky the competition kansas stingin manipuprrra llyits fans with\n",
            "i is diva my is dumb world bigg judged biothreatened those am entered\n",
            "i is young eastside my real siren answer mbmaninovember its of dedicated\n",
            "i is 21 my boss is dolls leads zihzih gniverits day plannin\n",
            "i these young world my world mean is worked vals extinjesus aggression be\n",
            "i is young savage my world is propheyeezy poetry us visual incredible about\n",
            "i these boss other young bitch duplicate rapped lia ors egypt am hail they\n",
            "i is di savage my world is darentilla identity its plannin ane\n",
            "i is john is lil world ass barrio equjustice teaching 83 they do\n",
            "i is thriller stupid same world one reaper psychogivjune fans they fact\n",
            "i is trill same damn rap world mons haminiting what of gods\n",
            "i is young killer niggas is best ssehart adjecritical of disaster true\n",
            "i is young nigga sucker its fuck rappresent flacko nac its where they\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peiRQSlx-USn"
      },
      "source": [
        "## eval.py stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdyXBE9wImO2"
      },
      "source": [
        "# ========== THIS IS CRUCIAL READ THIS ===========\n",
        "\n",
        "ctrl-f ****REMEMBER\n",
        "\n",
        "\n",
        "I left some comments of what to change when you are running stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KcAVPYP9vNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd674e8-7411-46f1-8511-8d2d389f421d"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.util import ngrams\n",
        "# from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import subprocess\n",
        "import locale\n",
        "from tqdm import tqdm\n",
        "from tqdm.autonotebook import trange\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "%load_ext google.colab.data_table\n",
        "\n",
        "# pip install transformers\n",
        "# pip install pronouncing\n",
        "\n",
        "# Self -bleu measures diversity between verse\n",
        "# Distinct-n measures diversity in a verse\n",
        "\n",
        "NUM_ARTISTS = 91\n",
        "# ****REMEMBER: need to change this to the right location\n",
        "RHYME_ANALYZER_JAR = '{}/RhymeApp.jar'.format(drive_folder)\n",
        "\n",
        "def sel_bleu_artist(artist_corpus):\n",
        "    '''\n",
        "    Corpus is a list[list[str]], which is a list of verses.  Use to compute self-bleu\n",
        "    '''\n",
        "    total = 0\n",
        "    list_of_references = []\n",
        "    hypotheses = []\n",
        "    for i in range(len(artist_corpus)):\n",
        "        list_of_references.append(artist_corpus[:i] + artist_corpus[i+1:])\n",
        "        hypotheses.append(artist_corpus[i])\n",
        "    return corpus_bleu(list_of_references, hypotheses)\n",
        "\n",
        "def sel_bleu_artist_avg(dataset, file_prefix):\n",
        "    \"\"\"\n",
        "    dataset is a list[list[list[str]]], or a list of artist_corpus\n",
        "    Returns per-artist self-bleu and dataset average\n",
        "    \"\"\"\n",
        "    dataset_bleu = []\n",
        "    for i in trange(len(dataset), desc=\"BLEU artist #\"):\n",
        "        artist = dataset[i]\n",
        "        artist_bleu = sel_bleu_artist(artist)\n",
        "        append_stat_to_txt_file(\"{}_sbleu\".format(file_prefix), artist_bleu)\n",
        "        dataset_bleu.append(artist_bleu)\n",
        "    return dataset_bleu, sum(dataset_bleu) / len(dataset_bleu)\n",
        "\n",
        "\n",
        "def distinct_n_verse(verse, n=1):\n",
        "    \"\"\"\n",
        "    Calculates distinct n grams in a verse\n",
        "    Verse should be list[str]\n",
        "    \"\"\"\n",
        "    if len(verse) == 0:\n",
        "        return 0.0  # Prevent a zero division\n",
        "    distinct_ngrams = set(ngrams(verse, n))\n",
        "    return len(distinct_ngrams) / len(verse)\n",
        "\n",
        "def distinct_n_artist(artist_corpus, n=1):\n",
        "    \"\"\"\n",
        "    Corpus is list[list[str]], or a list of verses\n",
        "    Returns average distinct-n for an artist\n",
        "    \"\"\"\n",
        "\n",
        "    verses_d = [distinct_n_verse(verse, n) for verse in artist_corpus]\n",
        "    return sum(verses_d) / len(artist_corpus)\n",
        "\n",
        "def distinct_n(corpus, n=1, file_prefix=''):\n",
        "    \"\"\"\n",
        "    Corpus is list[list[list[str]]], or a list of artist-verses\n",
        "    Returns list of artist distinct-n and average\n",
        "    \"\"\"\n",
        "    artist_d = []\n",
        "    for artist in corpus:\n",
        "        artist_d_n = distinct_n_artist(artist, n)\n",
        "        append_stat_to_txt_file(\"{}_d{}\".format(file_prefix, n), artist_d_n)\n",
        "        artist_d.append(artist_d_n)\n",
        "    return artist_d, sum(artist_d) / len(corpus)\n",
        "\n",
        "# def perplexity_artist(artist_corpus, tokenizer, model):\n",
        "#     \"\"\"\n",
        "#     Returns the average perplexity of a artist-corpus using gpt2 as LM\n",
        "#     \"\"\"\n",
        "#     ppls = []\n",
        "#     for verse in artist_corpus:\n",
        "#         tokenize_input = tokenizer.tokenize(verse)\n",
        "#         tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
        "#         loss=model(tensor_input, lm_labels=tensor_input)\n",
        "#         ppls.append(math.exp(loss))\n",
        "#     return sum(ppls) / len(ppls)\n",
        "\n",
        "\n",
        "def clean_lines(s):\n",
        "    # Removes extra lines, and strips lines\n",
        "    lines = [line.strip() for line in s.split('\\n')]\n",
        "    lines = list(filter(lambda s: s != '', lines))\n",
        "    # reconstruct the lines together\n",
        "    cleaned_lyrics = ''\n",
        "    for line in lines:\n",
        "        # concat lines together and add the end line token back\n",
        "        cleaned_lyrics = cleaned_lyrics + line + '\\n'\n",
        "    return cleaned_lyrics\n",
        "\n",
        "def calc_rhyme_density(bars):\n",
        "    \"\"\"\n",
        "    bars: list of bpe tokens\n",
        "    \"\"\"\n",
        "    text = \" \".join(bars).strip()\n",
        "    text = bpe_string_to_text(text)\n",
        "    text = clean_lines(text)\n",
        "    params = ['java', '-jar', RHYME_ANALYZER_JAR, text]\n",
        "    output = subprocess.check_output(params)\n",
        "\n",
        "    # convert to string\n",
        "    encoding = locale.getdefaultlocale()[1]\n",
        "    output = output.decode(encoding)\n",
        "\n",
        "    result = {}\n",
        "    for line in output.split('\\n'):\n",
        "        dv = line.split(':')\n",
        "\n",
        "        if len(dv) == 2:\n",
        "            key = dv[0].strip()\n",
        "            value = float(dv[1].strip())\n",
        "            result[key] = value\n",
        "\n",
        "    statistics = result\n",
        "    return statistics['Rhyme_Density'] if 'Rhyme_Density' in statistics else 0\n",
        "\n",
        "# def dope_learning_rhyme_scores(bars):\n",
        "#     text = \" \".join(bars)\n",
        "#     text = bpe_string_to_text(text)\n",
        "#     l = Lyrics(text=text, language='en-us')\n",
        "#     rl = l.get_avg_rhyme_length()\n",
        "#     return rl\n",
        "\n",
        "# def naive_rhyme_density(bars):\n",
        "#     total_syllables = 0\n",
        "#     rhymed_syllables = 0\n",
        "#     words_used = set([word for bar in bars for word in bar.split()])\n",
        "#     for bar in bars:\n",
        "#         for word in bar.split():\n",
        "#             p = pronouncing.phones_for_word(word)\n",
        "#             if len(p) == 0:\n",
        "#                 break\n",
        "#             syllables = pronouncing.syllable_count(p[0])\n",
        "#             total_syllables += syllables\n",
        "#             has_rhyme = False\n",
        "#             for rhyme in pronouncing.rhymes(word):\n",
        "#                 if has_rhyme:\n",
        "#                     break\n",
        "#                 if rhyme in words_used:\n",
        "#                     rhymed_syllables += syllables\n",
        "#                     has_rhyme = True\n",
        "#                     break\n",
        "#     return rhymed_syllables/total_syllables\n",
        "\n",
        "\n",
        "# TODO: Do artist similarity (cosine thing or crossentropy)\n",
        "\n",
        "def rhyme_density(corpus, file_prefix):\n",
        "    \"\"\"\n",
        "    Corpus is list[list[list[str]]], or a list of artist-verses\n",
        "    Returns list of artist distinct-n and average\n",
        "    \"\"\"\n",
        "    # print(\"\\n===== COMPUTING RD =====\\n\")\n",
        "    rds = []\n",
        "    for i in trange(len(corpus)):\n",
        "        artist = corpus[i]\n",
        "        artist_rd_sum = 0\n",
        "        for j in trange(len(artist), leave=False):\n",
        "            artist_rd_sum = artist_rd_sum + calc_rhyme_density(artist[j])\n",
        "        artist_rd = artist_rd_sum / len(artist)\n",
        "        append_stat_to_txt_file(\"{}_rd\".format(file_prefix), artist_rd)\n",
        "        rds.append(artist_rd)\n",
        "    return rds, sum(rds) / len(rds)\n",
        "\n",
        "def calc_tfidf_score(gen_artist, vocab, dataset_artist):\n",
        "    artist_dataset_verses_as_strings = [clean_lines(' '.join(verse)) for verse in dataset_artist]\n",
        "    # combining all dataset lyrics to one string\n",
        "    artist_dataset_all_verses = ' \\n '.join(artist_dataset_verses_as_strings)\n",
        "\n",
        "    all_verses_vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "    # vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
        "    all_verses_dataset_vectors = all_verses_vectorizer.fit_transform([artist_dataset_all_verses])\n",
        "\n",
        "    verse_vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "    verse_vectors = verse_vectorizer.fit_transform(artist_dataset_verses_as_strings)\n",
        "\n",
        "    avgs = []\n",
        "    maxs = []\n",
        "    for i in trange(len(gen_artist), desc='Verse # for Artist', leave=False):\n",
        "        verse = gen_artist[i]\n",
        "        cleaned_verse = [clean_lines(' '.join(verse))]\n",
        "\n",
        "        gen_to_all_verses_vector = all_verses_vectorizer.transform(cleaned_verse)\n",
        "        all_verses_sim = cosine_similarity(gen_to_all_verses_vector, all_verses_dataset_vectors).flatten()\n",
        "\n",
        "        gen_to_each_verse_vector = verse_vectorizer.transform(cleaned_verse)\n",
        "        verse_max_sim = cosine_similarity(gen_to_each_verse_vector, verse_vectors).flatten()\n",
        "\n",
        "        avgs.append(np.mean(all_verses_sim))\n",
        "        maxs.append(np.max(verse_max_sim))\n",
        "    return np.mean(avgs), np.mean(maxs)\n",
        "\n",
        "def get_tfidf_scores(corpus, file_prefix):\n",
        "    artist_to_verses_dataset = get_artist_to_verses_dataset('{}/train.json'.format(drive_folder))\n",
        "    with open('{}/bpe_string_token_to_int.json'.format(drive_folder)) as openfile:\n",
        "        vocab = json.load(openfile).keys()\n",
        "    average_tfidf_scores = []\n",
        "    max_tfidf_scores = []\n",
        "    for i in trange(len(corpus), desc='Artist #'):\n",
        "        gen_artist = corpus[i]\n",
        "        dataset_artist = artist_to_verses_dataset[i]\n",
        "        avg_score, max_score = calc_tfidf_score(gen_artist, vocab, dataset_artist)\n",
        "        append_stat_to_txt_file(\"{}_avg_sim_score\".format(file_prefix), avg_score)\n",
        "        append_stat_to_txt_file(\"{}_max_sim_score\".format(file_prefix), max_score)\n",
        "        average_tfidf_scores.append(avg_score)\n",
        "        max_tfidf_scores.append(max_score)\n",
        "    return average_tfidf_scores, max_tfidf_scores\n",
        "\n",
        "\n",
        "\n",
        "def get_lyric_blocks(song, input_format):\n",
        "    if input_format == \"raw_song\":\n",
        "        return [song['lyrics']]\n",
        "    elif input_format == \"verses\":\n",
        "        return [verse['lyrics'] for verse in song['verses']]\n",
        "    return []\n",
        "\n",
        "# def get_artist_to_verses_marked_verses():\n",
        "#     songs_dir = os.path.join(\"./\", \"data\", \"songs\", \"marked_verses\")\n",
        "#     songs_file = os.path.join(songs_dir, \"_LIST\")\n",
        "#     song_list = read_list_from_file(songs_file)\n",
        "#     artist_to_verses = {}\n",
        "#     for song_name in song_list:\n",
        "#         song_file = name_to_file_name(song_name)\n",
        "#         with open('{}/{}.json'.format(songs_dir, song_file)) as jsonfile:\n",
        "#             song = json.load(jsonfile)\n",
        "#             for verse in song['verses']:\n",
        "#                 artists = verse['artists'][0]\n",
        "#                 lyrics = verse['lyrics']\n",
        "#                 if verse['valid']:\n",
        "#                     if not artists in artist_to_verses:\n",
        "#                         artist_to_verses[artists] = []\n",
        "#                     artist_to_verses[artists].append(lyrics)\n",
        "#     print(\"Done reading things up\")\n",
        "#     return artist_to_verses\n",
        "\n",
        "def bpe_string_to_text(s):\n",
        "    return re.sub(r'(@@ )|(@@ ?$)', '', s)\n",
        "\n",
        "def clean_tokens(s):\n",
        "    s = re.sub(r' L | L', '\\n', s)\n",
        "    return re.sub(r'S ', '', s)\n",
        "\n",
        "def remove_duplicate_new_lines(l):\n",
        "    new_tokens = []\n",
        "    for i in range(0, len(l)):\n",
        "        curr_token = l[i]\n",
        "        if curr_token != '\\n':\n",
        "            new_tokens.append(curr_token)\n",
        "        elif i > 0:\n",
        "            prev_token = l[i-1]\n",
        "            if prev_token != '\\n':\n",
        "                new_tokens.append(curr_token)\n",
        "    return new_tokens            \n",
        "            \n",
        "\n",
        "def replace_start_with_new_line_from_list(l):\n",
        "    new_tokens = [token if token != 'S' else '\\n' for token in l]\n",
        "    return new_tokens\n",
        "\n",
        "def replace_end_with_new_line_from_list(l):\n",
        "    return [token if token != 'L' else '\\n' for token in l]\n",
        "\n",
        "def remove_end_tokens_from_list(l):\n",
        "    return list(filter(lambda x: x != 'L', l))\n",
        "\n",
        "def get_artist_to_verses_model_output(filename):\n",
        "    with open(filename) as openfile:\n",
        "        # this is in\n",
        "        # {\n",
        "            # 0 (artist id): [ (verses array)\n",
        "            #     [(tokens array) a, b, c],\n",
        "            # ]\n",
        "        # }\n",
        "        songs_json = json.load(openfile)\n",
        "    artist_to_verses = []\n",
        "    # instantiate list of lists, verses of artists\n",
        "    for _ in range(0, NUM_ARTISTS):\n",
        "        artist_to_verses.append([])\n",
        "    for artist in songs_json:\n",
        "        artist_index = int(artist) - 1\n",
        "        # Remove the L and replace S with \\n\n",
        "        artist_to_verses[artist_index] = [remove_duplicate_new_lines(replace_start_with_new_line_from_list(replace_end_with_new_line_from_list(verse))) for verse in songs_json[artist]]\n",
        "    return artist_to_verses\n",
        "\n",
        "def get_artist_to_verses_dataset(filename):\n",
        "    with open(filename) as openfile:\n",
        "        # {artist_id: ,\n",
        "        # lyrics: <string>}\n",
        "        verses_json = json.load(openfile)\n",
        "    artist_to_verses = []\n",
        "    # instantiate list of lists, verses of artists\n",
        "    for _ in range(0, NUM_ARTISTS):\n",
        "        artist_to_verses.append([])\n",
        "    for verse in verses_json:\n",
        "        artist_index = int(verse['artist_id']) - 1\n",
        "        lyrics_tokens = verse['lyrics'].split(' ')\n",
        "        cleaned_tokens = replace_start_with_new_line_from_list(remove_end_tokens_from_list(lyrics_tokens))\n",
        "        artist_to_verses[artist_index].append(cleaned_tokens)\n",
        "    return artist_to_verses\n",
        "\n",
        "def get_artist_to_verses_test():\n",
        "  return [[['a', 'b', 'c'], ['a' , 'z', 'b']], ['hjkhkjhkjtdytr', 'asd']]\n",
        "\n",
        "def append_stat_to_txt_file(filename, stat):\n",
        "    # ****REMEMBER: make sure this is the write location\n",
        "    with open(\"{}/{}.txt\".format(drive_folder, filename), 'a') as openfile:\n",
        "        openfile.write(str(stat))\n",
        "        openfile.write('\\n')\n",
        "\n",
        "def write_out_stats_to_file(filename, stats_list):\n",
        "    with open(filename, 'a') as openfile:\n",
        "        json.dump(stats_list, openfile)\n",
        "\n",
        "def artist_sim_matrix(start_artist, end_artist=91):\n",
        "    file_prefix = \"sim_matrix\"\n",
        "    artist_to_verses_dataset = get_artist_to_verses_dataset('{}/train.json'.format(drive_folder))\n",
        "    with open('{}/bpe_string_token_to_int.json'.format(drive_folder)) as openfile:\n",
        "        vocab = json.load(openfile).keys()\n",
        "    average_tfidf_scores = []\n",
        "    for i in trange(start_artist - 1, end_artist, desc='Artist #'):\n",
        "        dataset_artist = artist_to_verses_dataset[i]\n",
        "        for j in trange(len(artist_to_verses_dataset), desc='Artist comp #', leave=False):\n",
        "            compare_artist = artist_to_verses_dataset[j]\n",
        "            avg_score, _ = calc_tfidf_score(dataset_artist, vocab, compare_artist)\n",
        "            append_stat_to_txt_file(\"{}_artist_{}\".format(file_prefix, i + 1), avg_score)\n",
        "\n",
        "\n",
        "def main(file_prefix, read_file_name):\n",
        "    \"\"\"\n",
        "    the files will be of the form <file_prefix>_<metric>.txt\n",
        "    \"\"\"\n",
        "    # ****REMEMBER: you might need to change this to the correct function to\n",
        "    # format rhyme density, most likely will be something like\n",
        "    # get_artist_to_verses_model_output(<some file name>)\n",
        "    # you may have to write your own function if the format is different from\n",
        "    # the assumed format in that function\n",
        "    # ****REMEMBER: Make sure to start from the right artist\n",
        "    artist_to_verses = get_artist_to_verses_model_output(read_file_name)\n",
        "    per_artist_verses = artist_to_verses\n",
        "    rd, avg_rd = rhyme_density(per_artist_verses, file_prefix)\n",
        "    # ****REMEMBER: COMMENT THIS STUFF BELOW OUT IF YOU'RE ONLY DOING RHYME DENSITY\n",
        "    s_bleu, s_bleu_avg = sel_bleu_artist_avg(per_artist_verses, file_prefix)\n",
        "    distinct_1s, distinct_1_avg = distinct_n(per_artist_verses, 1, file_prefix)\n",
        "    distinct_2s, distinct_2_avg = distinct_n(per_artist_verses, 2, file_prefix)\n",
        "    distinct_3s, distinct_3_avg = distinct_n(per_artist_verses, 3, file_prefix)\n",
        "    avg_sim_score, max_sim_score = get_tfidf_scores(per_artist_verses, file_prefix)\n",
        "    return\n",
        "\n",
        "def read_list_from_file(list_path):\n",
        "    with open(list_path, encoding=\"utf-8\") as listfile:\n",
        "        l = listfile.readlines()\n",
        "    return [i.strip() for i in l]\n",
        "\n",
        "def list_to_floats(l):\n",
        "    return [float(i) for i in l]\n",
        "\n",
        "def summarize_metrics(file_prefix):\n",
        "    # RD diff\n",
        "    dataset_rds = list_to_floats(read_list_from_file('{}/train_dataset_rd.txt'.format(drive_folder)))\n",
        "    model_rds = list_to_floats(read_list_from_file('{}/{}_rd.txt'.format(drive_folder, file_prefix)))\n",
        "    rd_diff = mean_squared_error(dataset_rds, model_rds)\n",
        "    s_bleu = list_to_floats(read_list_from_file('{}/{}_sbleu.txt'.format(drive_folder, file_prefix)))\n",
        "    d1 = list_to_floats(read_list_from_file('{}/{}_d1.txt'.format(drive_folder, file_prefix)))\n",
        "    d2 = list_to_floats(read_list_from_file('{}/{}_d2.txt'.format(drive_folder, file_prefix)))\n",
        "    d3 = list_to_floats(read_list_from_file('{}/{}_d3.txt'.format(drive_folder, file_prefix)))\n",
        "    avg_sim = list_to_floats(read_list_from_file('{}/{}_avg_sim_score.txt'.format(drive_folder, file_prefix)))\n",
        "    max_sim = list_to_floats(read_list_from_file('{}/{}_max_sim_score.txt'.format(drive_folder, file_prefix)))\n",
        "    with open(\"{}/{}_metrics_summary.txt\".format(drive_folder, file_prefix), 'w') as openfile:\n",
        "        openfile.write(\"RD Difference: MSE {} \\n\".format(str(rd_diff)))\n",
        "        openfile.write(\"Self BLEU: Mean: {} Std: {}\\n\".format(str(np.mean(s_bleu)), str(np.std(s_bleu))))\n",
        "        openfile.write(\"Distinct 1: Mean: {} Std: {}\\n\".format(str(np.mean(d1)), str(np.std(d1))))\n",
        "        openfile.write(\"Distinct 2: Mean: {} Std: {}\\n\".format(str(np.mean(d2)), str(np.std(d2))))\n",
        "        openfile.write(\"Distinct 3: Mean: {} Std: {}\\n\".format(str(np.mean(d3)), str(np.std(d3))))\n",
        "        openfile.write(\"Avg Similarity: Mean: {} Std: {}\\n\".format(str(np.mean(avg_sim)), str(np.std(avg_sim))))\n",
        "        openfile.write(\"Max Similarity: Mean: {} Std: {}\\n\".format(str(np.mean(max_sim)), str(np.std(max_sim))))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ****REMEMBER: change the file name if necessary\n",
        "    pass\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMglSp_nCNTY"
      },
      "source": [
        "file_prefix = 'a9'\n",
        "verses_file = 'metrics/bart_a9/bart_a9_all_verses.json'\n",
        "\n",
        "main(file_prefix, '{}/{}'.format(drive_folder, verses_file))\n",
        "summarize_metrics(file_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zhcVRLeZaO"
      },
      "source": [
        "# Artist Sim matrix stuff "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He6nqWotNNv_"
      },
      "source": [
        "artist_sim_matrix(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT756EuyedqU"
      },
      "source": [
        "sim_matrix = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztEYbWqSfTcj"
      },
      "source": [
        "for i in range(0,91):\n",
        "    artist_id = i + 1\n",
        "    artist_scores_list = read_list_from_file(\"{}/sim_matrix_artist_{}.txt\".format(drive_folder, i + 1))\n",
        "    artist_scores = {j: float(artist_scores_list[j]) for j in range(0, len(artist_scores_list))}\n",
        "    sim_matrix = sim_matrix.append(artist_scores, ignore_index=True)\n",
        "sim_matrix.to_csv('{}/artist_sim_matrix.csv'.format(drive_folder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "q4wS9GdciTBO",
        "outputId": "c8f0263b-282c-4dd3-c219-0d9111edc85c"
      },
      "source": [
        "sim_matrix = pd.read_csv(\"{}/metrics/artist_sim_analysis/artist_sim_matrix.csv\".format(drive_folder))\n",
        "artist_names = ['21 savage', '6ix9ine', 'dr dre', 'earl sweatshirt', 'ice cube', 'kayne west', 'kendrick lamar', 'kid cudi', 'pusha t', 'tyler the creator']\n",
        "artist_indices = [1,4,22,25,35,43,45,46,66,85]\n",
        "artist_indices2 = [i - 1 for i in artist_indices]\n",
        "selected_matrix = sim_matrix.iloc[artist_indices, artist_indices]\n",
        "selected_matrix"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 0.4007793000183098,\n            'f': \"0.4007793000183098\",\n        },\n{\n            'v': 0.3979744410301157,\n            'f': \"0.3979744410301157\",\n        },\n{\n            'v': 0.36845829683756703,\n            'f': \"0.36845829683756703\",\n        },\n{\n            'v': 0.3928035031889973,\n            'f': \"0.3928035031889973\",\n        },\n{\n            'v': 0.3094037861347067,\n            'f': \"0.3094037861347067\",\n        },\n{\n            'v': 0.3983349871419764,\n            'f': \"0.3983349871419764\",\n        },\n{\n            'v': 0.3485260700338664,\n            'f': \"0.3485260700338664\",\n        },\n{\n            'v': 0.38597542559216463,\n            'f': \"0.38597542559216463\",\n        },\n{\n            'v': 0.3485417170001095,\n            'f': \"0.3485417170001095\",\n        },\n{\n            'v': 0.370582390213437,\n            'f': \"0.370582390213437\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 0.3844017459565445,\n            'f': \"0.3844017459565445\",\n        },\n{\n            'v': 0.3915068043957945,\n            'f': \"0.3915068043957945\",\n        },\n{\n            'v': 0.3679546610445881,\n            'f': \"0.3679546610445881\",\n        },\n{\n            'v': 0.3786119196676971,\n            'f': \"0.3786119196676971\",\n        },\n{\n            'v': 0.3076140849353323,\n            'f': \"0.3076140849353323\",\n        },\n{\n            'v': 0.3931648557187885,\n            'f': \"0.3931648557187885\",\n        },\n{\n            'v': 0.3464523078287135,\n            'f': \"0.3464523078287135\",\n        },\n{\n            'v': 0.3775778430529439,\n            'f': \"0.3775778430529439\",\n        },\n{\n            'v': 0.34859395218121986,\n            'f': \"0.34859395218121986\",\n        },\n{\n            'v': 0.3775118801144468,\n            'f': \"0.3775118801144468\",\n        }],\n [{\n            'v': 22,\n            'f': \"22\",\n        },\n{\n            'v': 0.4834319829178411,\n            'f': \"0.4834319829178411\",\n        },\n{\n            'v': 0.4944746682137769,\n            'f': \"0.4944746682137769\",\n        },\n{\n            'v': 0.4843380149288463,\n            'f': \"0.4843380149288463\",\n        },\n{\n            'v': 0.5077262381247084,\n            'f': \"0.5077262381247084\",\n        },\n{\n            'v': 0.4528540171988022,\n            'f': \"0.4528540171988022\",\n        },\n{\n            'v': 0.467711893940228,\n            'f': \"0.467711893940228\",\n        },\n{\n            'v': 0.4740049552838104,\n            'f': \"0.4740049552838104\",\n        },\n{\n            'v': 0.4975573531642094,\n            'f': \"0.4975573531642094\",\n        },\n{\n            'v': 0.4646399707841197,\n            'f': \"0.4646399707841197\",\n        },\n{\n            'v': 0.4623034759854018,\n            'f': \"0.4623034759854018\",\n        }],\n [{\n            'v': 25,\n            'f': \"25\",\n        },\n{\n            'v': 0.5060487448766952,\n            'f': \"0.5060487448766952\",\n        },\n{\n            'v': 0.5055455902790675,\n            'f': \"0.5055455902790675\",\n        },\n{\n            'v': 0.4889259553370761,\n            'f': \"0.4889259553370761\",\n        },\n{\n            'v': 0.5320191910220889,\n            'f': \"0.5320191910220889\",\n        },\n{\n            'v': 0.4852130277824546,\n            'f': \"0.4852130277824546\",\n        },\n{\n            'v': 0.4951014504659823,\n            'f': \"0.4951014504659823\",\n        },\n{\n            'v': 0.4908097928868029,\n            'f': \"0.4908097928868029\",\n        },\n{\n            'v': 0.5180722896718145,\n            'f': \"0.5180722896718145\",\n        },\n{\n            'v': 0.4696268612866454,\n            'f': \"0.4696268612866454\",\n        },\n{\n            'v': 0.4819910633390611,\n            'f': \"0.4819910633390611\",\n        }],\n [{\n            'v': 35,\n            'f': \"35\",\n        },\n{\n            'v': 0.4652747664733609,\n            'f': \"0.4652747664733609\",\n        },\n{\n            'v': 0.4828323162100862,\n            'f': \"0.4828323162100862\",\n        },\n{\n            'v': 0.4758339083754612,\n            'f': \"0.4758339083754612\",\n        },\n{\n            'v': 0.4900836513398396,\n            'f': \"0.4900836513398396\",\n        },\n{\n            'v': 0.43763491508944014,\n            'f': \"0.43763491508944014\",\n        },\n{\n            'v': 0.4477981365135339,\n            'f': \"0.4477981365135339\",\n        },\n{\n            'v': 0.4644056711755373,\n            'f': \"0.4644056711755373\",\n        },\n{\n            'v': 0.4843735738174709,\n            'f': \"0.4843735738174709\",\n        },\n{\n            'v': 0.4548235669656393,\n            'f': \"0.4548235669656393\",\n        },\n{\n            'v': 0.43626767905584746,\n            'f': \"0.43626767905584746\",\n        }],\n [{\n            'v': 43,\n            'f': \"43\",\n        },\n{\n            'v': 0.3930519383206823,\n            'f': \"0.3930519383206823\",\n        },\n{\n            'v': 0.4039573104661738,\n            'f': \"0.4039573104661738\",\n        },\n{\n            'v': 0.3971549663849017,\n            'f': \"0.3971549663849017\",\n        },\n{\n            'v': 0.4078785087849895,\n            'f': \"0.4078785087849895\",\n        },\n{\n            'v': 0.35634077860595764,\n            'f': \"0.35634077860595764\",\n        },\n{\n            'v': 0.3909986808483518,\n            'f': \"0.3909986808483518\",\n        },\n{\n            'v': 0.3882551059174972,\n            'f': \"0.3882551059174972\",\n        },\n{\n            'v': 0.4101774368779786,\n            'f': \"0.4101774368779786\",\n        },\n{\n            'v': 0.3875609740174178,\n            'f': \"0.3875609740174178\",\n        },\n{\n            'v': 0.3791282021774899,\n            'f': \"0.3791282021774899\",\n        }],\n [{\n            'v': 45,\n            'f': \"45\",\n        },\n{\n            'v': 0.4584636281198892,\n            'f': \"0.4584636281198892\",\n        },\n{\n            'v': 0.4680759594553092,\n            'f': \"0.4680759594553092\",\n        },\n{\n            'v': 0.4529166868406885,\n            'f': \"0.4529166868406885\",\n        },\n{\n            'v': 0.4730007312831073,\n            'f': \"0.4730007312831073\",\n        },\n{\n            'v': 0.4113567095471435,\n            'f': \"0.4113567095471435\",\n        },\n{\n            'v': 0.4543931147361751,\n            'f': \"0.4543931147361751\",\n        },\n{\n            'v': 0.4470633134494701,\n            'f': \"0.4470633134494701\",\n        },\n{\n            'v': 0.5022928475078489,\n            'f': \"0.5022928475078489\",\n        },\n{\n            'v': 0.4390331860274184,\n            'f': \"0.4390331860274184\",\n        },\n{\n            'v': 0.4305472563629793,\n            'f': \"0.4305472563629793\",\n        }],\n [{\n            'v': 46,\n            'f': \"46\",\n        },\n{\n            'v': 0.3581371050411372,\n            'f': \"0.3581371050411372\",\n        },\n{\n            'v': 0.36612998912757866,\n            'f': \"0.36612998912757866\",\n        },\n{\n            'v': 0.3559999418577528,\n            'f': \"0.3559999418577528\",\n        },\n{\n            'v': 0.371136055848452,\n            'f': \"0.371136055848452\",\n        },\n{\n            'v': 0.3200443738087911,\n            'f': \"0.3200443738087911\",\n        },\n{\n            'v': 0.3624583260743541,\n            'f': \"0.3624583260743541\",\n        },\n{\n            'v': 0.3495187680668323,\n            'f': \"0.3495187680668323\",\n        },\n{\n            'v': 0.37280443824170456,\n            'f': \"0.37280443824170456\",\n        },\n{\n            'v': 0.3476768663072207,\n            'f': \"0.3476768663072207\",\n        },\n{\n            'v': 0.3501908723293826,\n            'f': \"0.3501908723293826\",\n        }],\n [{\n            'v': 66,\n            'f': \"66\",\n        },\n{\n            'v': 0.4816463315045289,\n            'f': \"0.4816463315045289\",\n        },\n{\n            'v': 0.4870978367178891,\n            'f': \"0.4870978367178891\",\n        },\n{\n            'v': 0.4724012703109846,\n            'f': \"0.4724012703109846\",\n        },\n{\n            'v': 0.4992980828055861,\n            'f': \"0.4992980828055861\",\n        },\n{\n            'v': 0.4604067038981711,\n            'f': \"0.4604067038981711\",\n        },\n{\n            'v': 0.4685621645473079,\n            'f': \"0.4685621645473079\",\n        },\n{\n            'v': 0.4726716449481491,\n            'f': \"0.4726716449481491\",\n        },\n{\n            'v': 0.49820798075945294,\n            'f': \"0.49820798075945294\",\n        },\n{\n            'v': 0.4555569146535273,\n            'f': \"0.4555569146535273\",\n        },\n{\n            'v': 0.4594082021413139,\n            'f': \"0.4594082021413139\",\n        }],\n [{\n            'v': 85,\n            'f': \"85\",\n        },\n{\n            'v': 0.4123855649268165,\n            'f': \"0.4123855649268165\",\n        },\n{\n            'v': 0.4141999929282288,\n            'f': \"0.4141999929282288\",\n        },\n{\n            'v': 0.4020028704602077,\n            'f': \"0.4020028704602077\",\n        },\n{\n            'v': 0.4272298128486182,\n            'f': \"0.4272298128486182\",\n        },\n{\n            'v': 0.3653747390156347,\n            'f': \"0.3653747390156347\",\n        },\n{\n            'v': 0.4111946685922051,\n            'f': \"0.4111946685922051\",\n        },\n{\n            'v': 0.3884560692665661,\n            'f': \"0.3884560692665661\",\n        },\n{\n            'v': 0.4254179685098493,\n            'f': \"0.4254179685098493\",\n        },\n{\n            'v': 0.3873061779012028,\n            'f': \"0.3873061779012028\",\n        },\n{\n            'v': 0.3798200137132415,\n            'f': \"0.3798200137132415\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"0\"], [\"number\", \"3\"], [\"number\", \"21\"], [\"number\", \"24\"], [\"number\", \"34\"], [\"number\", \"42\"], [\"number\", \"44\"], [\"number\", \"45\"], [\"number\", \"65\"], [\"number\", \"84\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>3</th>\n",
              "      <th>21</th>\n",
              "      <th>24</th>\n",
              "      <th>34</th>\n",
              "      <th>42</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>65</th>\n",
              "      <th>84</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.400779</td>\n",
              "      <td>0.397974</td>\n",
              "      <td>0.368458</td>\n",
              "      <td>0.392804</td>\n",
              "      <td>0.309404</td>\n",
              "      <td>0.398335</td>\n",
              "      <td>0.348526</td>\n",
              "      <td>0.385975</td>\n",
              "      <td>0.348542</td>\n",
              "      <td>0.370582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.384402</td>\n",
              "      <td>0.391507</td>\n",
              "      <td>0.367955</td>\n",
              "      <td>0.378612</td>\n",
              "      <td>0.307614</td>\n",
              "      <td>0.393165</td>\n",
              "      <td>0.346452</td>\n",
              "      <td>0.377578</td>\n",
              "      <td>0.348594</td>\n",
              "      <td>0.377512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.483432</td>\n",
              "      <td>0.494475</td>\n",
              "      <td>0.484338</td>\n",
              "      <td>0.507726</td>\n",
              "      <td>0.452854</td>\n",
              "      <td>0.467712</td>\n",
              "      <td>0.474005</td>\n",
              "      <td>0.497557</td>\n",
              "      <td>0.464640</td>\n",
              "      <td>0.462303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.506049</td>\n",
              "      <td>0.505546</td>\n",
              "      <td>0.488926</td>\n",
              "      <td>0.532019</td>\n",
              "      <td>0.485213</td>\n",
              "      <td>0.495101</td>\n",
              "      <td>0.490810</td>\n",
              "      <td>0.518072</td>\n",
              "      <td>0.469627</td>\n",
              "      <td>0.481991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.465275</td>\n",
              "      <td>0.482832</td>\n",
              "      <td>0.475834</td>\n",
              "      <td>0.490084</td>\n",
              "      <td>0.437635</td>\n",
              "      <td>0.447798</td>\n",
              "      <td>0.464406</td>\n",
              "      <td>0.484374</td>\n",
              "      <td>0.454824</td>\n",
              "      <td>0.436268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.393052</td>\n",
              "      <td>0.403957</td>\n",
              "      <td>0.397155</td>\n",
              "      <td>0.407879</td>\n",
              "      <td>0.356341</td>\n",
              "      <td>0.390999</td>\n",
              "      <td>0.388255</td>\n",
              "      <td>0.410177</td>\n",
              "      <td>0.387561</td>\n",
              "      <td>0.379128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.458464</td>\n",
              "      <td>0.468076</td>\n",
              "      <td>0.452917</td>\n",
              "      <td>0.473001</td>\n",
              "      <td>0.411357</td>\n",
              "      <td>0.454393</td>\n",
              "      <td>0.447063</td>\n",
              "      <td>0.502293</td>\n",
              "      <td>0.439033</td>\n",
              "      <td>0.430547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.358137</td>\n",
              "      <td>0.366130</td>\n",
              "      <td>0.356000</td>\n",
              "      <td>0.371136</td>\n",
              "      <td>0.320044</td>\n",
              "      <td>0.362458</td>\n",
              "      <td>0.349519</td>\n",
              "      <td>0.372804</td>\n",
              "      <td>0.347677</td>\n",
              "      <td>0.350191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>0.481646</td>\n",
              "      <td>0.487098</td>\n",
              "      <td>0.472401</td>\n",
              "      <td>0.499298</td>\n",
              "      <td>0.460407</td>\n",
              "      <td>0.468562</td>\n",
              "      <td>0.472672</td>\n",
              "      <td>0.498208</td>\n",
              "      <td>0.455557</td>\n",
              "      <td>0.459408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.412386</td>\n",
              "      <td>0.414200</td>\n",
              "      <td>0.402003</td>\n",
              "      <td>0.427230</td>\n",
              "      <td>0.365375</td>\n",
              "      <td>0.411195</td>\n",
              "      <td>0.388456</td>\n",
              "      <td>0.425418</td>\n",
              "      <td>0.387306</td>\n",
              "      <td>0.379820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         3        21  ...        45        65        84\n",
              "1   0.400779  0.397974  0.368458  ...  0.385975  0.348542  0.370582\n",
              "4   0.384402  0.391507  0.367955  ...  0.377578  0.348594  0.377512\n",
              "22  0.483432  0.494475  0.484338  ...  0.497557  0.464640  0.462303\n",
              "25  0.506049  0.505546  0.488926  ...  0.518072  0.469627  0.481991\n",
              "35  0.465275  0.482832  0.475834  ...  0.484374  0.454824  0.436268\n",
              "43  0.393052  0.403957  0.397155  ...  0.410177  0.387561  0.379128\n",
              "45  0.458464  0.468076  0.452917  ...  0.502293  0.439033  0.430547\n",
              "46  0.358137  0.366130  0.356000  ...  0.372804  0.347677  0.350191\n",
              "66  0.481646  0.487098  0.472401  ...  0.498208  0.455557  0.459408\n",
              "85  0.412386  0.414200  0.402003  ...  0.425418  0.387306  0.379820\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "bT_ESMixn_zM",
        "outputId": "3c268d91-8821-49d5-b792-ae0db8cdae90"
      },
      "source": [
        "row_rename_dict = {artist_indices[i] : artist_names[i] for i in range(len(artist_names))}\n",
        "column_rename_dict2 = {str(artist_indices2[i]) : artist_names[i] for i in range(len(artist_names))}\n",
        "final_selected_matrix = selected_matrix.rename(index=row_rename_dict, columns=column_rename_dict2)\n",
        "final_selected_matrix = final_selected_matrix.applymap(lambda x: round(x, 3))\n",
        "final_selected_matrix"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[\"21 savage\",\n{\n            'v': 0.401,\n            'f': \"0.401\",\n        },\n{\n            'v': 0.398,\n            'f': \"0.398\",\n        },\n{\n            'v': 0.368,\n            'f': \"0.368\",\n        },\n{\n            'v': 0.393,\n            'f': \"0.393\",\n        },\n{\n            'v': 0.309,\n            'f': \"0.309\",\n        },\n{\n            'v': 0.398,\n            'f': \"0.398\",\n        },\n{\n            'v': 0.349,\n            'f': \"0.349\",\n        },\n{\n            'v': 0.386,\n            'f': \"0.386\",\n        },\n{\n            'v': 0.349,\n            'f': \"0.349\",\n        },\n{\n            'v': 0.371,\n            'f': \"0.371\",\n        }],\n [\"6ix9ine\",\n{\n            'v': 0.384,\n            'f': \"0.384\",\n        },\n{\n            'v': 0.392,\n            'f': \"0.392\",\n        },\n{\n            'v': 0.368,\n            'f': \"0.368\",\n        },\n{\n            'v': 0.379,\n            'f': \"0.379\",\n        },\n{\n            'v': 0.308,\n            'f': \"0.308\",\n        },\n{\n            'v': 0.393,\n            'f': \"0.393\",\n        },\n{\n            'v': 0.346,\n            'f': \"0.346\",\n        },\n{\n            'v': 0.378,\n            'f': \"0.378\",\n        },\n{\n            'v': 0.349,\n            'f': \"0.349\",\n        },\n{\n            'v': 0.378,\n            'f': \"0.378\",\n        }],\n [\"dr dre\",\n{\n            'v': 0.483,\n            'f': \"0.483\",\n        },\n{\n            'v': 0.494,\n            'f': \"0.494\",\n        },\n{\n            'v': 0.484,\n            'f': \"0.484\",\n        },\n{\n            'v': 0.508,\n            'f': \"0.508\",\n        },\n{\n            'v': 0.453,\n            'f': \"0.453\",\n        },\n{\n            'v': 0.468,\n            'f': \"0.468\",\n        },\n{\n            'v': 0.474,\n            'f': \"0.474\",\n        },\n{\n            'v': 0.498,\n            'f': \"0.498\",\n        },\n{\n            'v': 0.465,\n            'f': \"0.465\",\n        },\n{\n            'v': 0.462,\n            'f': \"0.462\",\n        }],\n [\"earl sweatshirt\",\n{\n            'v': 0.506,\n            'f': \"0.506\",\n        },\n{\n            'v': 0.506,\n            'f': \"0.506\",\n        },\n{\n            'v': 0.489,\n            'f': \"0.489\",\n        },\n{\n            'v': 0.532,\n            'f': \"0.532\",\n        },\n{\n            'v': 0.485,\n            'f': \"0.485\",\n        },\n{\n            'v': 0.495,\n            'f': \"0.495\",\n        },\n{\n            'v': 0.491,\n            'f': \"0.491\",\n        },\n{\n            'v': 0.518,\n            'f': \"0.518\",\n        },\n{\n            'v': 0.47,\n            'f': \"0.47\",\n        },\n{\n            'v': 0.482,\n            'f': \"0.482\",\n        }],\n [\"ice cube\",\n{\n            'v': 0.465,\n            'f': \"0.465\",\n        },\n{\n            'v': 0.483,\n            'f': \"0.483\",\n        },\n{\n            'v': 0.476,\n            'f': \"0.476\",\n        },\n{\n            'v': 0.49,\n            'f': \"0.49\",\n        },\n{\n            'v': 0.438,\n            'f': \"0.438\",\n        },\n{\n            'v': 0.448,\n            'f': \"0.448\",\n        },\n{\n            'v': 0.464,\n            'f': \"0.464\",\n        },\n{\n            'v': 0.484,\n            'f': \"0.484\",\n        },\n{\n            'v': 0.455,\n            'f': \"0.455\",\n        },\n{\n            'v': 0.436,\n            'f': \"0.436\",\n        }],\n [\"kayne west\",\n{\n            'v': 0.393,\n            'f': \"0.393\",\n        },\n{\n            'v': 0.404,\n            'f': \"0.404\",\n        },\n{\n            'v': 0.397,\n            'f': \"0.397\",\n        },\n{\n            'v': 0.408,\n            'f': \"0.408\",\n        },\n{\n            'v': 0.356,\n            'f': \"0.356\",\n        },\n{\n            'v': 0.391,\n            'f': \"0.391\",\n        },\n{\n            'v': 0.388,\n            'f': \"0.388\",\n        },\n{\n            'v': 0.41,\n            'f': \"0.41\",\n        },\n{\n            'v': 0.388,\n            'f': \"0.388\",\n        },\n{\n            'v': 0.379,\n            'f': \"0.379\",\n        }],\n [\"kendrick lamar\",\n{\n            'v': 0.458,\n            'f': \"0.458\",\n        },\n{\n            'v': 0.468,\n            'f': \"0.468\",\n        },\n{\n            'v': 0.453,\n            'f': \"0.453\",\n        },\n{\n            'v': 0.473,\n            'f': \"0.473\",\n        },\n{\n            'v': 0.411,\n            'f': \"0.411\",\n        },\n{\n            'v': 0.454,\n            'f': \"0.454\",\n        },\n{\n            'v': 0.447,\n            'f': \"0.447\",\n        },\n{\n            'v': 0.502,\n            'f': \"0.502\",\n        },\n{\n            'v': 0.439,\n            'f': \"0.439\",\n        },\n{\n            'v': 0.431,\n            'f': \"0.431\",\n        }],\n [\"kid cudi\",\n{\n            'v': 0.358,\n            'f': \"0.358\",\n        },\n{\n            'v': 0.366,\n            'f': \"0.366\",\n        },\n{\n            'v': 0.356,\n            'f': \"0.356\",\n        },\n{\n            'v': 0.371,\n            'f': \"0.371\",\n        },\n{\n            'v': 0.32,\n            'f': \"0.32\",\n        },\n{\n            'v': 0.362,\n            'f': \"0.362\",\n        },\n{\n            'v': 0.35,\n            'f': \"0.35\",\n        },\n{\n            'v': 0.373,\n            'f': \"0.373\",\n        },\n{\n            'v': 0.348,\n            'f': \"0.348\",\n        },\n{\n            'v': 0.35,\n            'f': \"0.35\",\n        }],\n [\"pusha t\",\n{\n            'v': 0.482,\n            'f': \"0.482\",\n        },\n{\n            'v': 0.487,\n            'f': \"0.487\",\n        },\n{\n            'v': 0.472,\n            'f': \"0.472\",\n        },\n{\n            'v': 0.499,\n            'f': \"0.499\",\n        },\n{\n            'v': 0.46,\n            'f': \"0.46\",\n        },\n{\n            'v': 0.469,\n            'f': \"0.469\",\n        },\n{\n            'v': 0.473,\n            'f': \"0.473\",\n        },\n{\n            'v': 0.498,\n            'f': \"0.498\",\n        },\n{\n            'v': 0.456,\n            'f': \"0.456\",\n        },\n{\n            'v': 0.459,\n            'f': \"0.459\",\n        }],\n [\"tyler the creator\",\n{\n            'v': 0.412,\n            'f': \"0.412\",\n        },\n{\n            'v': 0.414,\n            'f': \"0.414\",\n        },\n{\n            'v': 0.402,\n            'f': \"0.402\",\n        },\n{\n            'v': 0.427,\n            'f': \"0.427\",\n        },\n{\n            'v': 0.365,\n            'f': \"0.365\",\n        },\n{\n            'v': 0.411,\n            'f': \"0.411\",\n        },\n{\n            'v': 0.388,\n            'f': \"0.388\",\n        },\n{\n            'v': 0.425,\n            'f': \"0.425\",\n        },\n{\n            'v': 0.387,\n            'f': \"0.387\",\n        },\n{\n            'v': 0.38,\n            'f': \"0.38\",\n        }]],\n        columns: [[\"string\", \"index\"], [\"number\", \"21 savage\"], [\"number\", \"6ix9ine\"], [\"number\", \"dr dre\"], [\"number\", \"earl sweatshirt\"], [\"number\", \"ice cube\"], [\"number\", \"kayne west\"], [\"number\", \"kendrick lamar\"], [\"number\", \"kid cudi\"], [\"number\", \"pusha t\"], [\"number\", \"tyler the creator\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>21 savage</th>\n",
              "      <th>6ix9ine</th>\n",
              "      <th>dr dre</th>\n",
              "      <th>earl sweatshirt</th>\n",
              "      <th>ice cube</th>\n",
              "      <th>kayne west</th>\n",
              "      <th>kendrick lamar</th>\n",
              "      <th>kid cudi</th>\n",
              "      <th>pusha t</th>\n",
              "      <th>tyler the creator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21 savage</th>\n",
              "      <td>0.401</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.309</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.349</td>\n",
              "      <td>0.386</td>\n",
              "      <td>0.349</td>\n",
              "      <td>0.371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6ix9ine</th>\n",
              "      <td>0.384</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.379</td>\n",
              "      <td>0.308</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.349</td>\n",
              "      <td>0.378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dr dre</th>\n",
              "      <td>0.483</td>\n",
              "      <td>0.494</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.508</td>\n",
              "      <td>0.453</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.474</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>earl sweatshirt</th>\n",
              "      <td>0.506</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.489</td>\n",
              "      <td>0.532</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.491</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ice cube</th>\n",
              "      <td>0.465</td>\n",
              "      <td>0.483</td>\n",
              "      <td>0.476</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.438</td>\n",
              "      <td>0.448</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kayne west</th>\n",
              "      <td>0.393</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.397</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.356</td>\n",
              "      <td>0.391</td>\n",
              "      <td>0.388</td>\n",
              "      <td>0.410</td>\n",
              "      <td>0.388</td>\n",
              "      <td>0.379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kendrick lamar</th>\n",
              "      <td>0.458</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.453</td>\n",
              "      <td>0.473</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.447</td>\n",
              "      <td>0.502</td>\n",
              "      <td>0.439</td>\n",
              "      <td>0.431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kid cudi</th>\n",
              "      <td>0.358</td>\n",
              "      <td>0.366</td>\n",
              "      <td>0.356</td>\n",
              "      <td>0.371</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.362</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.373</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pusha t</th>\n",
              "      <td>0.482</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.472</td>\n",
              "      <td>0.499</td>\n",
              "      <td>0.460</td>\n",
              "      <td>0.469</td>\n",
              "      <td>0.473</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.456</td>\n",
              "      <td>0.459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tyler the creator</th>\n",
              "      <td>0.412</td>\n",
              "      <td>0.414</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.427</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.388</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.387</td>\n",
              "      <td>0.380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   21 savage  6ix9ine  ...  pusha t  tyler the creator\n",
              "21 savage              0.401    0.398  ...    0.349              0.371\n",
              "6ix9ine                0.384    0.392  ...    0.349              0.378\n",
              "dr dre                 0.483    0.494  ...    0.465              0.462\n",
              "earl sweatshirt        0.506    0.506  ...    0.470              0.482\n",
              "ice cube               0.465    0.483  ...    0.455              0.436\n",
              "kayne west             0.393    0.404  ...    0.388              0.379\n",
              "kendrick lamar         0.458    0.468  ...    0.439              0.431\n",
              "kid cudi               0.358    0.366  ...    0.348              0.350\n",
              "pusha t                0.482    0.487  ...    0.456              0.459\n",
              "tyler the creator      0.412    0.414  ...    0.387              0.380\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQQbTzBariVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "61f826d4-f7ee-4389-e130-a88315017c68"
      },
      "source": [
        "def highlight_max(s):\n",
        "    '''\n",
        "    highlight the maximum in a Series yellow.\n",
        "    '''\n",
        "    is_max = s == s.max()\n",
        "    return ['background-color: yellow' if v else '' for v in is_max]\n",
        "\n",
        "colored_matrix = final_selected_matrix.style.apply(highlight_max, axis = 1)\n",
        "colored_matrix"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col0,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col5,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col3,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col3,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col3,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col7,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col7,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col7,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col3,#T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col3{\n",
              "            background-color:  yellow;\n",
              "        }</style><table id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >21 savage</th>        <th class=\"col_heading level0 col1\" >6ix9ine</th>        <th class=\"col_heading level0 col2\" >dr dre</th>        <th class=\"col_heading level0 col3\" >earl sweatshirt</th>        <th class=\"col_heading level0 col4\" >ice cube</th>        <th class=\"col_heading level0 col5\" >kayne west</th>        <th class=\"col_heading level0 col6\" >kendrick lamar</th>        <th class=\"col_heading level0 col7\" >kid cudi</th>        <th class=\"col_heading level0 col8\" >pusha t</th>        <th class=\"col_heading level0 col9\" >tyler the creator</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >21 savage</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col0\" class=\"data row0 col0\" >0.401000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.398000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.368000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.393000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col4\" class=\"data row0 col4\" >0.309000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col5\" class=\"data row0 col5\" >0.398000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col6\" class=\"data row0 col6\" >0.349000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col7\" class=\"data row0 col7\" >0.386000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col8\" class=\"data row0 col8\" >0.349000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row0_col9\" class=\"data row0 col9\" >0.371000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >6ix9ine</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col0\" class=\"data row1 col0\" >0.384000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.392000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0.368000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0.379000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0.308000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col5\" class=\"data row1 col5\" >0.393000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col6\" class=\"data row1 col6\" >0.346000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col7\" class=\"data row1 col7\" >0.378000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col8\" class=\"data row1 col8\" >0.349000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row1_col9\" class=\"data row1 col9\" >0.378000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >dr dre</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.483000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.494000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0.484000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0.508000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col4\" class=\"data row2 col4\" >0.453000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col5\" class=\"data row2 col5\" >0.468000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col6\" class=\"data row2 col6\" >0.474000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col7\" class=\"data row2 col7\" >0.498000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col8\" class=\"data row2 col8\" >0.465000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row2_col9\" class=\"data row2 col9\" >0.462000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >earl sweatshirt</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0.506000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.506000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.489000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col3\" class=\"data row3 col3\" >0.532000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col4\" class=\"data row3 col4\" >0.485000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col5\" class=\"data row3 col5\" >0.495000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col6\" class=\"data row3 col6\" >0.491000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col7\" class=\"data row3 col7\" >0.518000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col8\" class=\"data row3 col8\" >0.470000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row3_col9\" class=\"data row3 col9\" >0.482000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >ice cube</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col0\" class=\"data row4 col0\" >0.465000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.483000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col2\" class=\"data row4 col2\" >0.476000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0.490000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col4\" class=\"data row4 col4\" >0.438000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col5\" class=\"data row4 col5\" >0.448000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col6\" class=\"data row4 col6\" >0.464000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col7\" class=\"data row4 col7\" >0.484000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col8\" class=\"data row4 col8\" >0.455000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row4_col9\" class=\"data row4 col9\" >0.436000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >kayne west</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col0\" class=\"data row5 col0\" >0.393000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.404000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col2\" class=\"data row5 col2\" >0.397000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0.408000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col4\" class=\"data row5 col4\" >0.356000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col5\" class=\"data row5 col5\" >0.391000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col6\" class=\"data row5 col6\" >0.388000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col7\" class=\"data row5 col7\" >0.410000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col8\" class=\"data row5 col8\" >0.388000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row5_col9\" class=\"data row5 col9\" >0.379000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >kendrick lamar</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col0\" class=\"data row6 col0\" >0.458000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.468000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col2\" class=\"data row6 col2\" >0.453000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col3\" class=\"data row6 col3\" >0.473000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col4\" class=\"data row6 col4\" >0.411000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col5\" class=\"data row6 col5\" >0.454000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col6\" class=\"data row6 col6\" >0.447000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col7\" class=\"data row6 col7\" >0.502000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col8\" class=\"data row6 col8\" >0.439000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row6_col9\" class=\"data row6 col9\" >0.431000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >kid cudi</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col0\" class=\"data row7 col0\" >0.358000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0.366000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col2\" class=\"data row7 col2\" >0.356000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col3\" class=\"data row7 col3\" >0.371000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col4\" class=\"data row7 col4\" >0.320000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col5\" class=\"data row7 col5\" >0.362000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col6\" class=\"data row7 col6\" >0.350000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col7\" class=\"data row7 col7\" >0.373000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col8\" class=\"data row7 col8\" >0.348000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row7_col9\" class=\"data row7 col9\" >0.350000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >pusha t</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col0\" class=\"data row8 col0\" >0.482000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col1\" class=\"data row8 col1\" >0.487000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col2\" class=\"data row8 col2\" >0.472000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col3\" class=\"data row8 col3\" >0.499000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col4\" class=\"data row8 col4\" >0.460000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col5\" class=\"data row8 col5\" >0.469000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col6\" class=\"data row8 col6\" >0.473000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col7\" class=\"data row8 col7\" >0.498000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col8\" class=\"data row8 col8\" >0.456000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row8_col9\" class=\"data row8 col9\" >0.459000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >tyler the creator</th>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col0\" class=\"data row9 col0\" >0.412000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col1\" class=\"data row9 col1\" >0.414000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col2\" class=\"data row9 col2\" >0.402000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col3\" class=\"data row9 col3\" >0.427000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col4\" class=\"data row9 col4\" >0.365000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col5\" class=\"data row9 col5\" >0.411000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col6\" class=\"data row9 col6\" >0.388000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col7\" class=\"data row9 col7\" >0.425000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col8\" class=\"data row9 col8\" >0.387000</td>\n",
              "                        <td id=\"T_5741cd62_38ad_11eb_a0b2_0242ac1c0002row9_col9\" class=\"data row9 col9\" >0.380000</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6cd6dfb2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdpKQT652K2A"
      },
      "source": [
        "# Testing stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujNRAjuI2Jwb",
        "outputId": "fa2d8a6c-d49a-431f-962e-40279bc0c9a8"
      },
      "source": [
        "l = ['a', 'asd', 'afsd', 'fad']\n",
        "list(filter(lambda x: x== 'a', l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfiN3y7c2Yqz"
      },
      "source": [
        "import codecs\n",
        "f = codecs.open('testfile', 'w', 'utf8')\n",
        "f.write(\"test\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAnDVK7gGM2N"
      },
      "source": [
        "from tqdm.autonotebook import trange\n",
        "from time import sleep\n",
        "\n",
        "for i in trange(5, leave=False):\n",
        "    for j in trange(10, leave=False):\n",
        "        sleep(.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYLFozZ8WYqh"
      },
      "source": [
        "with open(\"{}/testing_stuff.txt\".format(drive_folder), \"a\") as openfile:\n",
        "    openfile.write('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFPan8gmarMD",
        "outputId": "47b551c9-beed-4b66-c578-bc6bbada3e22"
      },
      "source": [
        "l = [1,2,3,4]\n",
        "l[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur-kmdSxhSxf"
      },
      "source": [
        "# bad bart\n",
        "# test = ['S', 'S', 'if', 'i', 'ever', 'got', 'caught', 'smokin', 'dope', 'it', 'must', 'be', 'adderall', 'L', 'S', 'S', 'you', 'gotta', 'trust', 'one', 'nigga', 'man', 'it', 'must', 'be', 'L', 'S', 'S', 'i', 'know', 'some', 'niggas', 'that', 'been', 'selling', 'dope', 'they', 'gon', 'sell', 'you', 'the', 'pot', 'L', 'S', 'S', 'they', 'brought', 'the', 'pistols', 'to', 'the', 'block', 'that', 'was', 'a', 'bastard', 'shot', 'L', 'S', 'S', 'im', 'a', 'slaughter', 'gang', 'with', 'shooters', 'gettin', 'chased', 'by', 'a', 'cop', 'L', 'S', 'S', 'nigga', 'act', 'like', 'he', 'dont', 'like', 'it', 'we', 'gon', 'run', 'him', 'over', 'with', 'the', 'glock', 'L', 'S', 'S', 'and', 'all', 'the', 'real', 'niggas', 'do', 'is', 'stay', 'humble', 'cause', 'they', 'dont', 'want', 'no', 'drama', 'L', 'S', 'S', 'a', 'few', 'bullets', 'will', 'cut', 'a', 'nigga', 'in', 'half', 'he', 'gon', 'need', 'a', 'morgue', 'L', 'S', 'S', 'i', 'got', 'my', 'pistols', 'dont', 'be', 'nice', 'we', 'use', 'a', 'body', 'bag', 'L', 'S', 'S', 'so', 'its', 'no', 'lacking', 'blood', 'on', 'the', 'dash', 'aint', 'no', 'blood', 'stains', 'nigga', 'L', 'S', 'S', 'slaughter', 'gang', 'freddie', 'kruger', 'playing', '21', 'games', 'nigga', 'L', 'S', 'S', '2', 'piece', 'chinchilla', 'L', 'S', 'S', 'or', 'you', 'could', 'call', 'me', 'frost', 'i', 'been', 'pullin', 'on', 'lame', 'niggas', 'L', 'S', 'S', 'i', 'been', 'pullin', 'on', 'bitches', 'i', 'been', 'kissin', 'on', 'some', 'hoes', 'L', 'S', 'S', 'all', 'you', 'do', 'is', 'trap', 'niggas', 'hope', 'the', 'cops', 'catch', 'us', 'L', 'S', 'S', 'bitch', 'i', 'can', 'feel', 'the', 'whoop', 'when', 'i', 'pulled', 'up', 'L']\n",
        "\n",
        "# cvae\n",
        "# test = [\"S\", \"bia\", \"heeee@@\", \"thing\", \"rising\", \"thow\", \"dents\", \"in\", \"ita\", \"kross\", \"ent\", \"iously\", \"ave\", \"middle\", \"michigan\", \"S\", \"af\", \"dream\", \"lookin\", \"hoar@@\", \"gains\", \"with\", \"biological\", \"o@@\", \"canvas\", \"tw\", \"muti@@\", \"os\", \"oblock\", \"station\", \"S\", \"scrip@@\", \"nutty\", \"look\", \"livin\", \"nasir\", \"with\", \"ac\", \"nets\", \"u@@\", \"morals\", \"bmm\", \"brighter\", \"hours\", \"bulls\", \"S\", \"code@@\", \"breecky\", \"look\", \"belligerent\", \"meh\", \"get\", \"avenue\", \"in\", \"gra\", \"sting\", \"philosophers\", \"power\", \"graphic\", \"85\", \"S\", \"spiteful\", \"type\", \"ily\", \"way\", \"sitions\", \"ladder\", \"when\", \"stra@@\", \"vie\", \"form\", \"ing@@\", \"mack@@\", \"the\", \"rival\", \"S\", \"jailed\", \"2\", \"carib@@\", \"convicts\", \"shooting\", \"virus\", \"at\", \"the\", \"extre@@\", \"hospitable\", \"holidays\", \"isms\", \"trees\", \"wrld\", \"S\", \"arose\", \"on\", \"chico\", \"obligation\", \"nyquil\", \"rydin\", \"worm\", \"from\", \"makeshift\", \"ored\", \"muny\", \"bass\", \"apollo\", \"mid@@\", \"S\", \"extremes\", \"5\", \"way\", \"tuxedo\", \"flashing\", \"magnums\", \"when\", \"blicky\", \"at\", \"ills\", \"changes\", \"highness\", \"ctic\", \"february\", \"S\", \"pari@@\", \"2\", \"meds\", \"summers\", \"dictator\", \"back\", \"ability\", \"with\", \"gos\", \"fran@@\", \"abyss\", \"tin\", \"geo@@\", \"vera\", \"S\", \"hookup\", \"tink\", \"way\", \"faking\", \"tweaking\", \"with\", \"cage\", \"L\", \"S\", \"oped\", \"2\", \"ured\", \"squadron\", \"x3\", \"55\", \"with\", \"board\", \"accu@@\", \"ambi@@\", \"mem\", \"68\", \"country\", \"hydro\", \"S\", \"grandmaster\", \"on\", \"okay\", \"entertainment\", \"lakes\", \"lala\", \"with\", \"simons\", \"priest\", \"lega@@\", \"to\", \"housing\", \"terms\", \"the\", \"S\", \"sah\", \"musk\", \"back\", \"forgot\", \"beehive\", \"on\", \"crisis\", \"twi@@\", \"tipper\", \"ine\", \"kman\", \"trees\", \"fight\", \"designing\", \"S\", \"hustlin\", \"mush\", \"type\", \"milo\", \"depends\", \"do@@\", \"u@@\", \"assa@@\", \"bab@@\", \"befriend\", \"apartments\", \"checks\", \"evi@@\", \"light@@\", \"S\", \"fun@@\", \"on\", \"boss\", \"scrapes\", \"75\", \"impalas\", \"and\", \"lung\", \"to\", \"madman\", \"carolina\", \"yonkers\", \"13\", \"dit\", \"S\", \"dian\", \"balls\", \"thats\", \"mmmmm\", \"bending\", \"in\", \"deliver@@\", \"tigger\", \"farewell\", \"put\", \"century\", \"shaolin\", \"on@@\", \"skyline\"]\n",
        "# bart\n",
        "# test= ['S', 'gang', 'parties', 'every', 'single', 'day', 'i', '<unk>', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'stra@@', '<unk>', '<unk>', 'woah', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'soul', '<unk>', '<unk>', 'for', '<unk>', '<unk>', 'you', '<unk>', '<unk>', 'believe', '<unk>', '<unk>', 'that', '<unk>', '<unk>', 'im', 'tryna', 'get', 'a', 'shot', 'at', '<unk>', '<unk>', 'der@@', '<unk>', '<unk>', 'doubt', '<unk>', 'S', 'mark', 'my', 'finger', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'all', 'on', '<unk>', '<unk>', 'right', '<unk>', '<unk>', 'act', 'on', 'me', 'and', 'make', 'me', '<unk>', '<unk>', 'heard', '<unk>', '<unk>', 'my', '<unk>', '<unk>', 'police', 'come', '<unk>', '<unk>', 'its', 'like', 'a', 'friend', 'of', 'mine', 'duckin', '<unk>', '<unk>', 'never', 'catch', '<unk>', '<unk>', 'doin', '<unk>', 'S', 'you', 'a', '<unk>', '<unk>', '<unk>', 'nigga', 'and', 'all', 'that', 'static', 'i', '<unk>', '<unk>', 'when', 'the', 'shit', '<unk>', '<unk>', 'five', '<unk>', '<unk>', 'it', '<unk>', '<unk>', 'my', '<unk>', '<unk>', 'lo@@', '<unk>', '<unk>', 'you', '<unk>', '<unk>', 'im', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'for', '<unk>', '<unk>', 'shit', '<unk>', 'for', 'my', 'niggas', '<unk>', '<unk>', 'S', 'when', 'im', 'locked', '<unk>', '<unk>', '<unk>', 'that', 'ass', 'down', 'thats', 'a', 'lock', '<unk>', '<unk>', 'im', '<unk>', '<unk>', 'right', '<unk>', '<unk>', 'sack', 'come', 'out', 'and', 'catch', 'a', 'fuck', 'nigga', 'when', 'he', 'come', 'home', '<unk>', '<unk>', 'crime', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'it', '<unk>', '<unk>', 'dont', '<unk>', '<unk>', 'on', 'shit', '<unk>', 'S', 'i', 'throw', 'it', 'by', 'the', '<unk>', '<unk>', '<unk>', 'u@@', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'mi@@', '<unk>', '<unk>', 'the', '<unk>', 'right', 'and', 'throw', 'it', 'up', 'like', 'a', 'motherfucking', '<unk>', '<unk>', 'dont', 'know', 'what', 'this', 'bitch', '<unk>', '<unk>', 're@@', '<unk>', '<unk>', 'religion', '<unk>', '<unk>', 'ver@@', '<unk>', '<unk>', 'feel', '<unk>', '<unk>', 'mines', 'S', 'and', 'im', 'from', 'the', 'dirty', '<unk>', '<unk>', '<unk>', 'a@@', '<unk>', '<unk>', 'like', 'im', 'from', '<unk>', '<unk>', 'already', '<unk>', '<unk>', 'my', '<unk>', '<unk>', 'yeah', 'yeah', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'right', '<unk>', '<unk>', 'dont', '<unk>', '<unk>', 'all', 'my', 'niggas', 'get', '<unk>', '<unk>', 'sleep', 'like', 'big', '<unk>', '<unk>', 'that', '<unk>', '<unk>', 'S', 'im', 'in', 'the', '<unk>', '<unk>', '<unk>', 'the', '<unk>', 'the', 'young', '<unk>', '<unk>', 'good', 'niggas', '<unk>', '<unk>', 'oh', 'doing', 'business', '<unk>', '<unk>', 'nigga', 'oh', '<unk>', '<unk>', 'rhyme', '<unk>', '<unk>', 'shit', 'we', 'gettin', 'money', 'shit', 'gettin', 'and', 'gettin', 'money', 'everyday', 'over', 'here', 'getting', 'money', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'head', 'getting', 'S', 'rock', 'a', '40', 'on', 'me', 'cause', 'im', 'on', '<unk>', '<unk>', '<unk>', 'br@@', '<unk>', '<unk>', 'gra@@', '<unk>', '<unk>', 'my', 'nigga', 'brand', 'new', '<unk>', '<unk>', 'wife', 'and', '<unk>', '<unk>', 'just', 'came', 'home', 'from', 'feelin', 'a', 'lil', '<unk>', '<unk>', 'right', 'from', 'doing', '<unk>', '<unk>', 'swa@@', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'oh', 'aint', 'S', 'oh', 'aint', 'no', 'mo', '<unk>', '<unk>', '<unk>', 'nigga', 'we', 'o', '<unk>', '<unk>', 'crime', '<unk>', '<unk>', 'four', 'my', 'nigga', 'we', '<unk>', '<unk>', 'ta@@', '<unk>', '<unk>', 'ea@@', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'yall', 'you', 'say', 'we', 'got', 'the', 'finest', 'bitches', 'in', 'the', '<unk>', 'tu@@', '<unk>', '<unk>', 'dont', 'leave', 'that', 'shit', 'cause', 'S', 'when', 'im', 'riding', 'off', 'in', 'the', '6', 'my', 'niggas', '<unk>', '<unk>', '<unk>', 'wont', 'wake', '<unk>', '<unk>', 'law', '<unk>', '<unk>', 'the', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'loud', 'the', '<unk>', 'wont', '<unk>', '<unk>', 'show', 'bitch', 'make', 'the', 'po', '<unk>', '<unk>', 'for', '<unk>', '<unk>', 'yall', 'my', '<unk>', '<unk>', 'blow', 'gon', 'post', '<unk>', 'S', 'oh', 'she', 'love', 'that', 'boy', 'ayy', 'she', 'gon', 'spend', 'it', 'on', '<unk>', '<unk>', '<unk>', 'shit', 'oh', 'she', 'miss', 'my', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'wont', '<unk>', '<unk>', 'huh', '<unk>', '<unk>', 'your', '<unk>', '<unk>', 'thats', '<unk>', '<unk>', 'when', 'i', 'run', 'shit', 'but', 'i', 'still', 'wont', 'leave', 'the', 'house', 'and', '<unk>', 'S', 'when', 'i', 'seen', 'a', 'ak', 'in', 'the', 'house', '<unk>', '<unk>', '<unk>', 'clothes', '<unk>', '<unk>', 'say', 'money', 'make', 'me', 'dance', '<unk>', '<unk>', 'that', '<unk>', '<unk>', 'my', '<unk>', '<unk>', 'o@@', '<unk>', '<unk>', 'all', '<unk>', '<unk>', 'your', '<unk>', '<unk>', 'i', '<unk>', '<unk>', 'try', 'and', 'do', 'like', 'me', 'just', 'like', '<unk>', '<unk>', 'it', 'S', 'run', 'up', 'on', 'you', 'run', 'up', '<unk>', '<unk>', '<unk>', '<mask>', '<unk>', '<unk>', 'yeah', 'wet', 'it', '<unk>', '<unk>', 'your', '<unk>', '<unk>', 'you', '<unk>', '<unk>', 'on@@', '<unk>', '<unk>', 'that', '<unk>', '<unk>', 'on', '<unk>', '<unk>', 'say', 'you', 'wanna', 'fuck', 'a', 'lil', '<unk>', '<unk>', 'right', 'fuck', 'lil', 'nigga', 'you', '<unk>', 'nigga', '<unk>', '<unk>', 'S', 'bitch', 'im', '<unk>', '<unk>', '<unk>', 'its', 'right', '<unk>', '<unk>', 'yall', '<unk>', '<unk>', 'blow', '<unk>', '<unk>', 'ction@@', '<unk>', '<unk>', 'a@@', '<unk>', '<unk>', 'your', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'ohh', '<unk>', '<unk>', 'for', '<unk>', '<unk>', 're@@', '<unk>', '<unk>', 'yeah', '<unk>', '<unk>', 'crime', 'dont', 'touch', 'my', '<unk>', '<unk>', 'my', '<unk>', 'crime', '<unk>', 'S', '<unk>', '<unk>', '<unk>', 'check', 'lets', 'get', 'to', 'this', '<unk>', '<unk>', 'hand', '<unk>', '<unk>', 'show', '<unk>', '<unk>', 'me', '<unk>', '<unk>', 'crime', '<unk>', '<unk>', 'r@@', '<unk>', '<unk>', 'for', 'my', '<unk>', '<unk>', 'my', '<unk>', 'h@@', '<unk>', '<unk>', 'hope', 'that', 'these', 'hoes', 'got', '<unk>', '<unk>', 'it', '<unk>', '<unk>', 'got', '<unk>', 'my', 'bible', 'written', 'S', 'yeah', '<unk>', '<unk>', '<unk>', 'the', '<unk>', '<unk>', 'crime', 'for', 'your', 'boy', 'and', 'your', '<unk>', '<unk>', 'bra@@', '<unk>', '<unk>', 'you', '<unk>', '<unk>', 'justice', 'for', 'your', '<unk>', 'crime', '<unk>', '<unk>', 'it', '<unk>', '<unk>', 'your', '<unk>', 'e@@', '<unk>', '<unk>', 'for', 'your', 'bitch', 'for', 'making', 'me', '<unk>', '<unk>', 'war', '<unk>', '<unk>', 'my', '<unk>']\n",
        "\n",
        "test= ['S', 'in', 'a', 'bimmer', 'hustling', 'like', 'its', 'a', 'cage', 'L', 'S', 'goin', 'in', 'my', 'bimmer', 'now', 'its', 'outer', 'space', 'L', 'S', 'that', 'bitch', 'funny', 'and', 'i', 'promise', 'i', 'aint', 'talkin', 'bout', 'cake', 'i', 'dont', 'want', 'no', 'cake', 'L', 'S', 'tell', 'these', 'hoes', 'sit', 'back', 'and', 'laugh', 'while', 'i', 'show', 'her', 'how', 'to', 'get', 'it', 'yeah', 'L', 'S', 'and', 'they', 'actin', 'like', 'they', 'got', 'no', 'soul', 'got', 'so', 'many', 'cups', 'you', 'need', 'a', 'belly', 'tuck', 'or', 'some', 'ass@@', 'ets', 'L', 'S', 'pull', 'up', 'on', 'your', 'baby', 'mama', 'im', 'like', 'lil', 'kodak', 'why', 'you', 'say', 'that', 'L', 'S', 'got', 'my', 'chopper', 'from', 'my', 'mama', 'yeah', 'i', 'used', 'to', 'keep', 'it', 'silent', 'L', 'S', 'lil', 'jeezy', 'be', 'on', 'them', 'snitches', 'lil', 'nigga', 'he', 'be', 'on', 'some', 'go@@', 'ba@@', 'b', 'shit', 'L', 'S', 'they', 'tried', 'to', 'pay', 'me', 'for', 'my', 'jewels', 'i', 'aint', 'talkin', 'bout', 'no', 'hockey', 'shit', 'L', 'S', 'young', 'savage', 'dope', 'fiend', 'with', 'a', 'chopper', 'get', 'the', 'glock', 'and', 'a', 'ruger', 'bitch', 'L', 'S', 'i', 'aint', 'got', 'no', 'time', 'to', 'snitch', 'bitch', 'i', 'need', 'some', 'handles', 'L', 'S', 'ill', 'fuck', 'yo', 'sister', 'then', 'i', 'fuck', 'yo', 'thot', 'bitch', 'i', 'keep', 'goin', 'to', 'sleep', 'L', 'S', 'bitch', 'i', 'keep', 'on', 'goin', 'to', 'sleep', 'im', 'tryna', 'make', 'a', 'million', 'off', 'of', 'this', 'dope', 'L', 'S', 'how', 'you', 'got', 'me', 'pissed', 'off', 'i', 'got', 'the', 'shottie', 'bitch', 'im', 'cold', 'like', 'a', 'tough', 'talk', 'L', 'S', 'aye', 'bang', 'bang', 'L', 'S', 'ridin', 'with', 'my', 'toolie', 'on', 'my', 'hip', 'no', 'crease', 'L']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M-T5rl1JPHk",
        "outputId": "c2739ef7-ec32-497f-8e94-a537bfd0fcb8"
      },
      "source": [
        "gittest = remove_duplicate_new_lines(replace_start_with_new_line_from_list(replace_end_with_new_line_from_list(test)))\n",
        "print(' '.join(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in a bimmer hustling like its a cage \n",
            " goin in my bimmer now its outer space \n",
            " that bitch funny and i promise i aint talkin bout cake i dont want no cake \n",
            " tell these hoes sit back and laugh while i show her how to get it yeah \n",
            " and they actin like they got no soul got so many cups you need a belly tuck or some ass@@ ets \n",
            " pull up on your baby mama im like lil kodak why you say that \n",
            " got my chopper from my mama yeah i used to keep it silent \n",
            " lil jeezy be on them snitches lil nigga he be on some go@@ ba@@ b shit \n",
            " they tried to pay me for my jewels i aint talkin bout no hockey shit \n",
            " young savage dope fiend with a chopper get the glock and a ruger bitch \n",
            " i aint got no time to snitch bitch i need some handles \n",
            " ill fuck yo sister then i fuck yo thot bitch i keep goin to sleep \n",
            " bitch i keep on goin to sleep im tryna make a million off of this dope \n",
            " how you got me pissed off i got the shottie bitch im cold like a tough talk \n",
            " aye bang bang \n",
            " ridin with my toolie on my hip no crease \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRrw4Vy4JoVP"
      },
      "source": [
        "for i in trange(5, 10):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptFcYzmqMjk9"
      },
      "source": [
        "append_stat_to_txt_file(\"12313testse\", 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUfq-FUqOkJI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}